{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Of Content:\n",
    "* [Downloading Data](#Downloading-dataset)\n",
    "* [Using ResNet152](#Downloading-ResNet152-model-of-CNN-family)\n",
    "* [Creating Custom Dataset Class](#Creating-Custom-Dataset-class-to-further-use-during-training)\n",
    "* [Label Smoothing](#LabelS)\n",
    "* [Training the Model](#training)\n",
    "* [Why CLIP](#CLIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-Mttp5IcPHl"
   },
   "outputs": [],
   "source": [
    "!wget https://people.cs.pitt.edu/~kovashka/ads/annotations_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0HesP_8crnG"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/ads-dataset/resnet_negative.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwcFYr98OVAZ"
   },
   "outputs": [],
   "source": [
    "!sudo apt install parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYAWWDeAdnbS"
   },
   "outputs": [],
   "source": [
    "!parallel wget https://storage.googleapis.com/ads-dataset/subfolder-{}.zip ::: {1..9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM_P51cwLsYa"
   },
   "outputs": [],
   "source": [
    "!unzip /content/resnet_negative.zip -d /content/images/NotAdv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data processing to organise it for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHZ4ngloNTxg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def copy_images(set_path):\n",
    "    source_directory = os.path.join(\"images\", \"NotAdv\", \"resnet_training_negatives\", set_path)\n",
    "    destination_directory = os.path.join(\"images\", \"NotAdv\")\n",
    "\n",
    "    for file_name in os.listdir(source_directory):\n",
    "        source_file = os.path.join(source_directory, file_name)\n",
    "        destination_file = os.path.join(destination_directory, file_name)\n",
    "\n",
    "        shutil.copy(source_file, destination_file)\n",
    "        print(f\"Copied {file_name} from {set_path} to NotAdv folder.\")\n",
    "\n",
    "        os.remove(source_file)\n",
    "        print(f\"Deleted {file_name} from {set_path}.\")\n",
    "\n",
    "sets = [\"set\" + str(i) for i in range(5)]\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(copy_images, sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDvUTDcXOQQO"
   },
   "outputs": [],
   "source": [
    "!rm -R /content/images/NotAdv/resnet_training_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N7c6lnpWWgf"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def unzip_zip_file(zip_path, output_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    print(f\"Extracted {zip_path}\")\n",
    "\n",
    "def unzip_all_zip_files(directory, num_files, output_dir):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for i in range(1, num_files + 1):\n",
    "            zip_file = f\"subfolder-{i}.zip\"\n",
    "            zip_path = os.path.join(directory, zip_file)\n",
    "            if os.path.exists(zip_path):\n",
    "                executor.submit(unzip_zip_file, zip_path, output_dir)\n",
    "            else:\n",
    "                print(f\"Zip file {zip_file} not found.\")\n",
    "\n",
    "directory = '/content'\n",
    "num_files = 9\n",
    "output_dir = 'images'\n",
    "\n",
    "unzip_all_zip_files(directory, num_files, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sg5jZQcXHSfL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_directory = \"/content/images\"\n",
    "destination_directory = \"/content/images/Adv\"\n",
    "\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)\n",
    "y\n",
    "for folder_name in range(1, 11):\n",
    "    source_folder = os.path.join(source_directory, str(folder_name))\n",
    "\n",
    "    if os.path.exists(source_folder):\n",
    "\n",
    "        for file_name in os.listdir(source_folder):\n",
    "            source_file = os.path.join(source_folder, file_name)\n",
    "            shutil.copy(source_file, destination_directory)\n",
    "            print(f\"Copied {file_name} from folder {folder_name} to Adv folder.\")\n",
    "    else:\n",
    "        print(f\"Folder {folder_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbLTIiF9ISlt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_directory = \"/content/images\"\n",
    "\n",
    "for folder_name in range(1, 11):\n",
    "    folder_path = os.path.join(source_directory, str(folder_name))\n",
    "\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Deleted folder {folder_name}.\")\n",
    "    else:\n",
    "        print(f\"Folder {folder_name} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvfsi_8FFSIa"
   },
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAGS6HTVR6u-"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "timm.list_models('*resnet*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading ResNet152 model of CNN family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Oy0YTSbEzq_"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model('resnet152', pretrained=False, num_classes=2)\n",
    "model = model.to('cuda') # Move to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Custom Dataset class to further use during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49bytIMuEztr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "Image.MAX_IMAGE_PIXELS = 99979202110\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.images = self.load_images()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def load_images(self):\n",
    "        images = []\n",
    "        for class_dir in self.classes:\n",
    "            class_idx = self.class_to_idx[class_dir]\n",
    "            class_path = os.path.join(self.root_dir, class_dir)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                images.append((img_path, class_idx))\n",
    "        return images\n",
    "\n",
    "\n",
    "    root_dir = '/content/images'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHexbp35Ezwr",
    "outputId": "f8c8b379-c9e3-4b0e-f606-74d95e868a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images = 25000\n",
      "Testing images = 8000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import random\n",
    "\n",
    "dataset = CustomDataset(root_dir, transform=transform)\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "random.shuffle(indices)\n",
    "train_size = 25000\n",
    "test_size = 8000\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:train_size+test_size]\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=64, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
    "test_loader = DataLoader(dataset, batch_size=64, sampler=torch.utils.data.SubsetRandomSampler(test_indices))\n",
    "\n",
    "print(\"Training images =\", len(train_indices))\n",
    "print(\"Testing images =\", len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyJVNA47SqqB"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"LabelS\"></a>\n",
    "### Label smoothing (Also already available in PyTorch API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwNY4FqsbD_c"
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(SmoothCrossEntropyLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        log_prob = nn.functional.log_softmax(input, dim=-1)\n",
    "        weight = input.new_ones(input.size()) * (self.smoothing / (input.size(-1) - 1.))\n",
    "\n",
    "        target = target.to(input.device)\n",
    "        weight = weight.to(input.device)\n",
    "\n",
    "        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n",
    "        loss = (-weight * log_prob).sum(dim=-1).mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "criterion = SmoothCrossEntropyLoss(smoothing=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"training\"></a>\n",
    "### Defining configs like loss criterion and optimizer to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BixYdD9sSUVx",
    "outputId": "84a05460-f70e-41a1-f19a-156c30d46755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 2/391, 0.51% done\n",
      "Epoch 1/1, Batch 4/391, 1.02% done\n",
      "Epoch 1/1, Batch 6/391, 1.53% done\n",
      "Epoch 1/1, Batch 8/391, 2.05% done\n",
      "Epoch 1/1, Batch 10/391, 2.56% done\n",
      "Epoch 1/1, Batch 12/391, 3.07% done\n",
      "Epoch 1/1, Batch 14/391, 3.58% done\n",
      "Epoch 1/1, Batch 16/391, 4.09% done\n",
      "Epoch 1/1, Batch 18/391, 4.60% done\n",
      "Epoch 1/1, Batch 20/391, 5.12% done\n",
      "Epoch 1/1, Batch 22/391, 5.63% done\n",
      "Epoch 1/1, Batch 24/391, 6.14% done\n",
      "Epoch 1/1, Batch 26/391, 6.65% done\n",
      "Epoch 1/1, Batch 28/391, 7.16% done\n",
      "Epoch 1/1, Batch 30/391, 7.67% done\n",
      "Epoch 1/1, Batch 32/391, 8.18% done\n",
      "Epoch 1/1, Batch 34/391, 8.70% done\n",
      "Epoch 1/1, Batch 36/391, 9.21% done\n",
      "Epoch 1/1, Batch 38/391, 9.72% done\n",
      "Epoch 1/1, Batch 40/391, 10.23% done\n",
      "Epoch 1/1, Batch 42/391, 10.74% done\n",
      "Epoch 1/1, Batch 44/391, 11.25% done\n",
      "Epoch 1/1, Batch 46/391, 11.76% done\n",
      "Epoch 1/1, Batch 48/391, 12.28% done\n",
      "Epoch 1/1, Batch 50/391, 12.79% done\n",
      "Epoch 1/1, Batch 52/391, 13.30% done\n",
      "Epoch 1/1, Batch 54/391, 13.81% done\n",
      "Epoch 1/1, Batch 56/391, 14.32% done\n",
      "Epoch 1/1, Batch 58/391, 14.83% done\n",
      "Epoch 1/1, Batch 60/391, 15.35% done\n",
      "Epoch 1/1, Batch 62/391, 15.86% done\n",
      "Epoch 1/1, Batch 64/391, 16.37% done\n",
      "Epoch 1/1, Batch 66/391, 16.88% done\n",
      "Epoch 1/1, Batch 68/391, 17.39% done\n",
      "Epoch 1/1, Batch 70/391, 17.90% done\n",
      "Epoch 1/1, Batch 72/391, 18.41% done\n",
      "Epoch 1/1, Batch 74/391, 18.93% done\n",
      "Epoch 1/1, Batch 76/391, 19.44% done\n",
      "Epoch 1/1, Batch 78/391, 19.95% done\n",
      "Epoch 1/1, Batch 80/391, 20.46% done\n",
      "Epoch 1/1, Batch 82/391, 20.97% done\n",
      "Epoch 1/1, Batch 84/391, 21.48% done\n",
      "Epoch 1/1, Batch 86/391, 21.99% done\n",
      "Epoch 1/1, Batch 88/391, 22.51% done\n",
      "Epoch 1/1, Batch 90/391, 23.02% done\n",
      "Epoch 1/1, Batch 92/391, 23.53% done\n",
      "Epoch 1/1, Batch 94/391, 24.04% done\n",
      "Epoch 1/1, Batch 96/391, 24.55% done\n",
      "Epoch 1/1, Batch 98/391, 25.06% done\n",
      "Epoch 1/1, Batch 100/391, 25.58% done\n",
      "Epoch 1/1, Batch 102/391, 26.09% done\n",
      "Epoch 1/1, Batch 104/391, 26.60% done\n",
      "Epoch 1/1, Batch 106/391, 27.11% done\n",
      "Epoch 1/1, Batch 108/391, 27.62% done\n",
      "Epoch 1/1, Batch 110/391, 28.13% done\n",
      "Epoch 1/1, Batch 112/391, 28.64% done\n",
      "Epoch 1/1, Batch 114/391, 29.16% done\n",
      "Epoch 1/1, Batch 116/391, 29.67% done\n",
      "Epoch 1/1, Batch 118/391, 30.18% done\n",
      "Epoch 1/1, Batch 120/391, 30.69% done\n",
      "Epoch 1/1, Batch 122/391, 31.20% done\n",
      "Epoch 1/1, Batch 124/391, 31.71% done\n",
      "Epoch 1/1, Batch 126/391, 32.23% done\n",
      "Epoch 1/1, Batch 128/391, 32.74% done\n",
      "Epoch 1/1, Batch 130/391, 33.25% done\n",
      "Epoch 1/1, Batch 132/391, 33.76% done\n",
      "Epoch 1/1, Batch 134/391, 34.27% done\n",
      "Epoch 1/1, Batch 136/391, 34.78% done\n",
      "Epoch 1/1, Batch 138/391, 35.29% done\n",
      "Epoch 1/1, Batch 140/391, 35.81% done\n",
      "Epoch 1/1, Batch 142/391, 36.32% done\n",
      "Epoch 1/1, Batch 144/391, 36.83% done\n",
      "Epoch 1/1, Batch 146/391, 37.34% done\n",
      "Epoch 1/1, Batch 148/391, 37.85% done\n",
      "Epoch 1/1, Batch 150/391, 38.36% done\n",
      "Epoch 1/1, Batch 152/391, 38.87% done\n",
      "Epoch 1/1, Batch 154/391, 39.39% done\n",
      "Epoch 1/1, Batch 156/391, 39.90% done\n",
      "Epoch 1/1, Batch 158/391, 40.41% done\n",
      "Epoch 1/1, Batch 160/391, 40.92% done\n",
      "Epoch 1/1, Batch 162/391, 41.43% done\n",
      "Epoch 1/1, Batch 164/391, 41.94% done\n",
      "Epoch 1/1, Batch 166/391, 42.46% done\n",
      "Epoch 1/1, Batch 168/391, 42.97% done\n",
      "Epoch 1/1, Batch 170/391, 43.48% done\n",
      "Epoch 1/1, Batch 172/391, 43.99% done\n",
      "Epoch 1/1, Batch 174/391, 44.50% done\n",
      "Epoch 1/1, Batch 176/391, 45.01% done\n",
      "Epoch 1/1, Batch 178/391, 45.52% done\n",
      "Epoch 1/1, Batch 180/391, 46.04% done\n",
      "Epoch 1/1, Batch 182/391, 46.55% done\n",
      "Epoch 1/1, Batch 184/391, 47.06% done\n",
      "Epoch 1/1, Batch 186/391, 47.57% done\n",
      "Epoch 1/1, Batch 188/391, 48.08% done\n",
      "Epoch 1/1, Batch 190/391, 48.59% done\n",
      "Epoch 1/1, Batch 192/391, 49.10% done\n",
      "Epoch 1/1, Batch 194/391, 49.62% done\n",
      "Epoch 1/1, Batch 196/391, 50.13% done\n",
      "Epoch 1/1, Batch 198/391, 50.64% done\n",
      "Epoch 1/1, Batch 200/391, 51.15% done\n",
      "Epoch 1/1, Batch 202/391, 51.66% done\n",
      "Epoch 1/1, Batch 204/391, 52.17% done\n",
      "Epoch 1/1, Batch 206/391, 52.69% done\n",
      "Epoch 1/1, Batch 208/391, 53.20% done\n",
      "Epoch 1/1, Batch 210/391, 53.71% done\n",
      "Epoch 1/1, Batch 212/391, 54.22% done\n",
      "Epoch 1/1, Batch 214/391, 54.73% done\n",
      "Epoch 1/1, Batch 216/391, 55.24% done\n",
      "Epoch 1/1, Batch 218/391, 55.75% done\n",
      "Epoch 1/1, Batch 220/391, 56.27% done\n",
      "Epoch 1/1, Batch 222/391, 56.78% done\n",
      "Epoch 1/1, Batch 224/391, 57.29% done\n",
      "Epoch 1/1, Batch 226/391, 57.80% done\n",
      "Epoch 1/1, Batch 228/391, 58.31% done\n",
      "Epoch 1/1, Batch 230/391, 58.82% done\n",
      "Epoch 1/1, Batch 232/391, 59.34% done\n",
      "Epoch 1/1, Batch 234/391, 59.85% done\n",
      "Epoch 1/1, Batch 236/391, 60.36% done\n",
      "Epoch 1/1, Batch 238/391, 60.87% done\n",
      "Epoch 1/1, Batch 240/391, 61.38% done\n",
      "Epoch 1/1, Batch 242/391, 61.89% done\n",
      "Epoch 1/1, Batch 244/391, 62.40% done\n",
      "Epoch 1/1, Batch 246/391, 62.92% done\n",
      "Epoch 1/1, Batch 248/391, 63.43% done\n",
      "Epoch 1/1, Batch 250/391, 63.94% done\n",
      "Epoch 1/1, Batch 252/391, 64.45% done\n",
      "Epoch 1/1, Batch 254/391, 64.96% done\n",
      "Epoch 1/1, Batch 256/391, 65.47% done\n",
      "Epoch 1/1, Batch 258/391, 65.98% done\n",
      "Epoch 1/1, Batch 260/391, 66.50% done\n",
      "Epoch 1/1, Batch 262/391, 67.01% done\n",
      "Epoch 1/1, Batch 264/391, 67.52% done\n",
      "Epoch 1/1, Batch 266/391, 68.03% done\n",
      "Epoch 1/1, Batch 268/391, 68.54% done\n",
      "Epoch 1/1, Batch 270/391, 69.05% done\n",
      "Epoch 1/1, Batch 272/391, 69.57% done\n",
      "Epoch 1/1, Batch 274/391, 70.08% done\n",
      "Epoch 1/1, Batch 276/391, 70.59% done\n",
      "Epoch 1/1, Batch 278/391, 71.10% done\n",
      "Epoch 1/1, Batch 280/391, 71.61% done\n",
      "Epoch 1/1, Batch 282/391, 72.12% done\n",
      "Epoch 1/1, Batch 284/391, 72.63% done\n",
      "Epoch 1/1, Batch 286/391, 73.15% done\n",
      "Epoch 1/1, Batch 288/391, 73.66% done\n",
      "Epoch 1/1, Batch 290/391, 74.17% done\n",
      "Epoch 1/1, Batch 292/391, 74.68% done\n",
      "Epoch 1/1, Batch 294/391, 75.19% done\n",
      "Epoch 1/1, Batch 296/391, 75.70% done\n",
      "Epoch 1/1, Batch 298/391, 76.21% done\n",
      "Epoch 1/1, Batch 300/391, 76.73% done\n",
      "Epoch 1/1, Batch 302/391, 77.24% done\n",
      "Epoch 1/1, Batch 304/391, 77.75% done\n",
      "Epoch 1/1, Batch 306/391, 78.26% done\n",
      "Epoch 1/1, Batch 308/391, 78.77% done\n",
      "Epoch 1/1, Batch 310/391, 79.28% done\n",
      "Epoch 1/1, Batch 312/391, 79.80% done\n",
      "Epoch 1/1, Batch 314/391, 80.31% done\n",
      "Epoch 1/1, Batch 316/391, 80.82% done\n",
      "Epoch 1/1, Batch 318/391, 81.33% done\n",
      "Epoch 1/1, Batch 320/391, 81.84% done\n",
      "Epoch 1/1, Batch 322/391, 82.35% done\n",
      "Epoch 1/1, Batch 324/391, 82.86% done\n",
      "Epoch 1/1, Batch 326/391, 83.38% done\n",
      "Epoch 1/1, Batch 328/391, 83.89% done\n",
      "Epoch 1/1, Batch 330/391, 84.40% done\n",
      "Epoch 1/1, Batch 332/391, 84.91% done\n",
      "Epoch 1/1, Batch 334/391, 85.42% done\n",
      "Epoch 1/1, Batch 336/391, 85.93% done\n",
      "Epoch 1/1, Batch 338/391, 86.45% done\n",
      "Epoch 1/1, Batch 340/391, 86.96% done\n",
      "Epoch 1/1, Batch 342/391, 87.47% done\n",
      "Epoch 1/1, Batch 344/391, 87.98% done\n",
      "Epoch 1/1, Batch 346/391, 88.49% done\n",
      "Epoch 1/1, Batch 348/391, 89.00% done\n",
      "Epoch 1/1, Batch 350/391, 89.51% done\n",
      "Epoch 1/1, Batch 352/391, 90.03% done\n",
      "Epoch 1/1, Batch 354/391, 90.54% done\n",
      "Epoch 1/1, Batch 356/391, 91.05% done\n",
      "Epoch 1/1, Batch 358/391, 91.56% done\n",
      "Epoch 1/1, Batch 360/391, 92.07% done\n",
      "Epoch 1/1, Batch 362/391, 92.58% done\n",
      "Epoch 1/1, Batch 364/391, 93.09% done\n",
      "Epoch 1/1, Batch 366/391, 93.61% done\n",
      "Epoch 1/1, Batch 368/391, 94.12% done\n",
      "Epoch 1/1, Batch 370/391, 94.63% done\n",
      "Epoch 1/1, Batch 372/391, 95.14% done\n",
      "Epoch 1/1, Batch 374/391, 95.65% done\n",
      "Epoch 1/1, Batch 376/391, 96.16% done\n",
      "Epoch 1/1, Batch 378/391, 96.68% done\n",
      "Epoch 1/1, Batch 380/391, 97.19% done\n",
      "Epoch 1/1, Batch 382/391, 97.70% done\n",
      "Epoch 1/1, Batch 384/391, 98.21% done\n",
      "Epoch 1/1, Batch 386/391, 98.72% done\n",
      "Epoch 1/1, Batch 388/391, 99.23% done\n",
      "Epoch 1/1, Batch 390/391, 99.74% done\n",
      "Epoch 1/1, Train Loss: 0.1838, Train Accuracy: 79.28%\n",
      "Validation Accuracy: 79.69%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# Loss Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i+1) % 2 == 0:\n",
    "            percent_epoch_done = (i+1) / len(train_loader) * 100\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(train_loader)}, {percent_epoch_done:.2f}% done\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"CLIP\"></a>\n",
    "\n",
    "\n",
    "### ResNet achieved accuracy of 79.28%. But these models still Lack complex understanding of the image like what a symbol in image respresent. For example an image of 'dove' represents peace.\n",
    "\n",
    "### So we should find a solution which merges the visual representation as well as the sentiments and other complex representation of image\n",
    "\n",
    "## This is where CLIP model comes, which merges the Image and Text into same modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wi9h0tHFjJwz"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Adv_Model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMgGF7G5XR35"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u44ZMxpvffex"
   },
   "outputs": [],
   "source": [
    "!pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TiCpNG5qVN3b",
    "outputId": "4475e6bc-4a44-40e1-d39d-d59595e44c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  cudaStreamIsCapturing         0.02%     340.000us         0.02%     340.000us       1.545us       0.000us         0.00%       0.000us       0.000us           220  \n",
      "                                             cudaMalloc        11.72%     162.314ms        11.72%     162.314ms       1.168ms       0.000us         0.00%       0.000us       0.000us           139  \n",
      "                                        cudaMemcpyAsync         0.33%       4.518ms         0.33%       4.518ms       4.518ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       4.265ms         0.46%       4.265ms       4.265ms             1  \n",
      "                                  cudaStreamSynchronize         0.00%      27.000us         0.00%      27.000us      27.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                     cudaGetDeviceCount         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                   cudaDriverGetVersion         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                 cudaDeviceGetAttribute         0.01%     111.000us         0.01%     111.000us       2.846us       0.000us         0.00%       0.000us       0.000us            39  \n",
      "                             cudaGetDeviceProperties_v2         0.02%     283.000us         0.02%     283.000us     141.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                              cudaStreamCreateWithFlags         1.19%      16.423ms         1.19%      16.423ms       1.026ms       0.000us         0.00%       0.000us       0.000us            16  \n",
      "                                        cudaMemsetAsync         0.00%      51.000us         0.00%      51.000us      12.750us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         0.00%       3.000us       3.000us             1  \n",
      "                                          cudaHostAlloc         0.79%      11.002ms         0.79%      11.002ms      11.002ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                               cudaHostGetDevicePointer         0.00%       3.000us         0.00%       3.000us       3.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                               cudaFree        51.63%     714.930ms        51.63%     714.930ms     142.986ms       0.000us         0.00%       0.000us       0.000us             5  \n",
      "                                   cudaGetSymbolAddress         0.98%      13.523ms         0.98%      13.523ms      13.523ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaStreamGetPriority         0.00%      33.000us         0.00%      33.000us       1.031us       0.000us         0.00%       0.000us       0.000us            32  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.00%      31.000us         0.00%      31.000us       0.969us       0.000us         0.00%       0.000us       0.000us            32  \n",
      "                                       cudaLaunchKernel        32.09%     444.301ms        32.09%     444.301ms       1.491ms       0.000us         0.00%       0.000us       0.000us           298  \n",
      "void cask_cudnn_infer::computeOffsetsKernel<false, f...         0.00%       0.000us         0.00%       0.000us       0.000us       9.000us         0.00%       9.000us       3.000us             3  \n",
      "      cudnn_infer_volta_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us       1.285ms         0.14%       1.285ms       1.285ms             1  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      10.554ms         1.15%      10.554ms     329.812us            32  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.566ms         0.28%       2.566ms     855.333us             3  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      17.927ms         1.95%      17.927ms     560.219us            32  \n",
      "void conv2d_c1_k1_nhwc_kernel<float, float, float, f...         0.00%       0.000us         0.00%       0.000us       0.000us      86.651ms         9.44%      86.651ms       2.988ms            29  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         1.20%      16.650ms         1.20%      16.650ms     416.250us       0.000us         0.00%       0.000us       0.000us            40  \n",
      "                                 volta_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     625.894ms        68.17%     625.894ms      11.809ms            53  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      33.470ms         3.65%      33.470ms       1.195ms            28  \n",
      "void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      51.739ms         5.64%      51.739ms     923.911us            56  \n",
      "                                  volta_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      51.113ms         5.57%      51.113ms      17.038ms             3  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       8.668ms         0.94%       8.668ms     309.571us            28  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      12.336ms         1.34%      12.336ms     440.571us            28  \n",
      "cudnn_infer_volta_scudnn_128x128_relu_exp_medium_nhw...         0.00%       0.000us         0.00%       0.000us       0.000us      11.595ms         1.26%      11.595ms       5.798ms             2  \n",
      "                                         cudaMemGetInfo         0.00%      38.000us         0.00%      38.000us      38.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize         0.00%      19.000us         0.00%      19.000us      19.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.385s\n",
      "Self CUDA time total: 918.075ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdypsqET_zNg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
